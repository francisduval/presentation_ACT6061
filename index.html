<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Tarification avec données télématiques</title>
    <meta charset="utf-8" />
    <meta name="author" content="Francis Duval" />
    <meta name="date" content="2023-03-08" />
    <script src="libs/header-attrs-2.20/header-attrs.js"></script>
    <link rel="stylesheet" href="theme_cara.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">




class: title-slide
background-image: url(images/logo_chaire.jpg), url(images/background.jpg)
background-size: 30%, cover
background-position: 98% 98%, center

.titre-page-titre[Introduction à l'apprentissage profond]
&lt;br /&gt;
.sous-titre-page-titre[Modèles actuariels en assurance non-vie]
&lt;br /&gt;
&lt;br /&gt;
***
&lt;br /&gt;
&lt;br /&gt;
.sous-sous-titre-page-titre[.mon-style-bleu[par] Francis Duval &lt;br /&gt; .mon-style-bleu[à] l'Université du Québec à Montréal &lt;br /&gt; .mon-style-bleu[le] 14 mars 2023]

---

# Qu'est-ce que l'apprentissage profond?

&lt;img src="images/ai_ml_dl.png" width="95%" style="display: block; margin: auto;" /&gt;

- L'apprentissage profond est la grande majorité du temps effectué avec des .gras-bleu[réseaux de neurones profonds], c'est-à-dire des réseaux de neurones avec plusieurs couches cachées.

???

**Intelligence**
- La capacité de traiter l'information pour éclairer les décisions futures ou pour effectuer des tâches

**Intelligence artificielle**
- Algorithme qui essaie d'imiter l'intelligence humaine.

**Machine learning**
- Apprendre à un algorithme comment résoudre la tâche sans être explicitement programmé pour le faire.

**Apprentissage profond**
- Machine learning qui va encore plus loin et qui va extraire automatiquement l'information utile à partir des données brutes.

---

# Pourquoi l'apprentissage profond?

&lt;img src="images/dl_faces.jpg" width="100%" style="display: block; margin: auto;" /&gt;

???

- En machine learning, on donne habituellement en entrée au modèle des features (ou variables explicatives) qui sont conçues « à la main » à partir des données brutes.
- Les GLMs sont un exemple d'algorithme de machine learning.
- Par exemple, en assurance automobile, on va définir un ensemble de features qu'on va donner en entrée au modèle: âge, sexe, région, marque de voiture, échelle bonus-malus, etc.
- Le machine learning permet de résoudre une grande variété de tâches, mais peut ne pas être apte à des tâches plus complexes dans lesquelles la création de features à partir des données brutes n'est pas simple.
- Par exemple, en détection de visages, où les données brutes sont des pixels, ce ne serait pas clair quelles transformations il faut faire avant de les donner en entrée à notre GLM pour que celui-ci soit capable de reconnaître un visage. 
- On pourrait lui dire « si tu vois une bouche et un nez, c'est probablement un visage ». Mais comment extraire les features « bouche » et « nez » à partir des pixels?
- La bonne manière d'approcher ce type de problème est d'utiliser un réseau de neurones, qui va apprendre lui-même des features à partir des données brutes, et ce de manière hiérarchique.
- Par exemple, les premières couches cachées vont apprendre les caractéristiques de bas niveau de visages, c'est-à-dire des lignes.
- Les couches intermédiaires vont apprendre des caractéristiques de plus haut niveau, comme des nez et des yeux.
- Finalement, la dernière couche apprend des caractéristiques de haut niveau, ici des visages complets.

---

# Pourquoi l'apprentissage profond?

## Exemple: on veut tarifer les assurés avec leurs données télématiques

.pull-left[
**Machine learning**
- On va extraire des features « à la main » à partir des données brutes. Par exemple:
  - nb. freinages brusques
  - nb. accélérations brusques
  - % conduite le jour/soir/nuit
  - vitesse moyenne
  - etc.
- On utilise ensuite ces features extraites « à la main » dans un algorithme de machine learning, comme un GLM. 
]

.pull-right[
**Deep learning**
- On donne typiquement les données sous un format plus brute à l'algorithme de deep learning. Par exemple, on pourrait lui donner:
  - les données de trajets seconde-par-seconde sous un certain format
  - les résumés de trajets sous un certain format
- Celui-ci va lui-même créer les features qu'il trouve pertinentes.
- Noter qu'il y a quand même un certain travail d'ingénierie de données à faire. Par exemple, il est peu probable qu'une date (stockée sous `R` en nombre de jours depuis 1970) soit pertinente pour la tarification.
]

---

# Pourquoi l'apprentissage profond?

.pull-left[
&lt;img src="images/deep_learning.png" width="100%" style="display: block; margin: auto auto auto 0;" /&gt;
]

.pull-right[
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
## Machine learning 
&lt;br&gt;
## vs
&lt;br&gt;
## Deep learning
]

---

background-image: url("images/timeline.png")
background-position: 10% 50%
background-size: 25%

# Petit historique

.pull-right-65[
## Pourquoi maintenant?

1. **Données massives**
  - Plus facile de nos jours de collecter et stocker de grandes quantités de données.
2. **Hardware**
  - Puissance de calcul a beaucoup augmenté (et a diminué en prix) depuis quelques décennies.
  - GPUs (Graphics Processing Units)
3. **Software**
  - Nouveaux logiciels qui facilite l'implémentation de modèles de deep learning sont apparus:
    - Torch for `R`
    - PyTorch
    - TensorFlow
    - etc.
]

&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;

- Aussi, plusieurs avancées théoriques depuis quelques décennies: **backpropagation**, résolution du **vanishing (ou exploding) gradient problem**, etc.


???

- Les réseaux de neurones existent depuis longtemps (plusieurs décennies).
- Pourquoi alors semblent-ils avoir subit une hausse de popularité dans les dernières années?
- Pour plusieurs raisons:
  - Plus de données qu'avant
  - Meilleurs ordinateurs
  - Nouveaux logiciels pour facilier l'implémentation
- Aussi:
  - Découverte de la rétro-propagation dans les années 80
  - Résolution du problème d'explosion et de « vanishing » du gradient dans les réseaux de neurones profonds.

---

# Qu'est-ce qu'un réseau de neurones (concrètement)?

## Perceptron

**Le perceptron est l'instance la plus simple d'un réseau de neurones. Il est en quelque sorte la « brique » qui permet de construire des réseaux de neurones plus complexes.**

&lt;img src="images/perceptron.png" width="65%" style="display: block; margin: auto;" /&gt;

???

- Donc un perceptron est une fonction qui va:
  - multiplier chaque input par un poids,
  - additioner les résultats des multiplications,
  - transformer le nombre obtenu avec une fonction d'activation.
- Noter que la fonction d'activation peut être la fonction identité, si notre output est élément des réels
- Si notre variable réponse est binaire, on peut utiliser la fonction d'activation sigmoide, et alors on obtient un perceptron qui est très similaire à la régression logistique.
- Si notre variable réponse est un nombre entier positif, on peut utiliser la fonction d'activation exponentielle, et alors on obtient un perceptron qui est très similaire à la régression Poisson.
- Note: on peut aussi voir la fonction de prédiction d'un perceptron comme le produit scalaire du vecteur d'inputs `\(\boldsymbol{x}\)` avec le vecteur de poids `\(\boldsymbol{W}\)`, suivi de l'application de la fonction d'activation `\(g\)`.

---

# Qu'est-ce qu'un réseau de neurones (concrètement)?

## Exemple

- Un actuaire veut estimer la probabilité de réclamer pour des assuré.es en se basant sur 2 prédicteurs (inputs), c'est-à-dire l'**âge de l'assuré.e** et l'**âge de son véhicule**. 
- L'actuaire considère un perceptron avec une fonction d'activation **sigmoide**. Après avoir entrainé le perceptron sur une base de données, il obtient les poids suivants:
  - `\(w_0\)` = -2, 
  - `\(w_{\texttt{age_ass}}\)` = -0.02,
  - `\(w_{\texttt{age_veh}}\)` = -0.01.

&lt;br&gt;&lt;br&gt;
**Estimer la probabilité de réclamer pour un assuré de 25 ans avec un véhicule de 5 ans.**

???

`\begin{align*}
  \widehat{y} &amp;= \frac{1}{1+e^{-(-2-0.02 \times 25 -0.01 \times 5)}}\\
  &amp;= 0.07243
\end{align*}`

---

# Qu'est-ce qu'un réseau de neurones (concrètement)?

## Ajout de couches cachées

- Un perceptron est bien, mais ne permet qu'une fonction de prédiction linéaire (par rapport aux inputs).
- Ajouter des couches cachées permet d'obtenir un fonction de prédiction bien plus flexible. Lorsqu'il y a au moins 1 couche cachée, on parle de **perceptron multicouches**.


### Exercice
- Aller sur le site [playground.tensorflow.org](https://playground.tensorflow.org).
- Entrainer un perceptron avec fonction d'activation **sigmoide** utilisant les 2 premiers inputs `\(x_1\)` et `\(x_2\)` sur le **premier jeu de données de classification**.
  - Remarquer que la fonction de prédiction obtenue est linéaire, alors que la tâche à effectuer ne l'est pas (c'est un cercle).    
- Ajouter `\(x_1^2\)` et `\(x_2^2\)` comme inputs et entrainer le modèle.
  - Le modèle est maintenant capable de bien séparer les 2 classes, sauf qu'il a fallu penser à créer les 2 nouveaux inputs `\(x_1^2\)` et `\(x_2^2\)`.
- Utiliser seulement `\(x_1\)` et `\(x_2\)` comme inputs, mais ajouter une **couche cachée à 3 neurones**. Entrainer le modèle.
  - Le modèle a maintenant une fonction de prédiction plus raisonnable.

---

background-image: url("images/graphe_perceptron.png")
background-position: 80% 41%
background-size: 70%

# Qu'est-ce qu'un réseau de neurones (concrètement)?

### Perceptron multicouches (exemple à 1 couche cachée de 3 neurones cachés)

&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;

La fonction de prédiction peut être écrite sous forme matricielle: `\(\widehat{y} = g\left[\boldsymbol{w}^{(2)}\times g\left(\boldsymbol{w}^{(1)}\boldsymbol{x} + \boldsymbol{b}^{(1)}\right) + \boldsymbol{b}_1^{(2)}\right]\)`, où « `\(\times\)` » est la multiplication matricielle standard et où:

`\begin{align*}
  \boldsymbol{x} =  \begin{bmatrix} x_1\\x_2 \end{bmatrix}, \quad \boldsymbol{w}^{(1)} = \begin{bmatrix} w_{11}^{(1)} &amp; w_{21}^{(1)}\\w_{12}^{(1)} &amp; w_{22}^{(1)} \\ w_{13}^{(1)} &amp; w_{23}^{(1)} \end{bmatrix}, \quad \boldsymbol{w}^{(2)} = \begin{bmatrix} w_1^{(2)} &amp; w_2^{(2)} &amp; w_3^{(2)} \end{bmatrix}, \quad \boldsymbol{b^{(1)}} = \begin{bmatrix} b_1^{(1)} &amp; b_2^{(1)} &amp; b_3^{(1)} \end{bmatrix}, \quad \boldsymbol{b}_1^{2} = \begin{bmatrix} b_1^{(2)} \end{bmatrix}.
\end{align*}`

???

- Remarquer que la fonction de prédiction est déjà relativement complexe avec seulement une couche cachée de 3 neurones. 
- En effet, pour seulement 2 inputs, on a déjà 13 paramètres. C'est pour ça que les réseaux de neurones sont capables de résoudre des tâches complexes.
- La linéarité est brisée par les fonctions d'activation `\(g\)`. Sans celles-ci, la fonction de prédiction serait complètement linéaire.

---

# Entrainer un réseau de neurones

### Fonction de perte

- Entrainer le réseau = trouver de « bonnes » valeurs pour les paramètres `\(\boldsymbol{w}\)` et `\(\boldsymbol{b}\)`.
- Bonnes valeurs de paramètres `\(\longrightarrow\)` valeurs qui donnent des prédictions `\(\widehat{y}\)` « proches » des réponses `\(y\)`.
- Pour définir « proche », on doit se choisir une **fonction de perte**.
- Exemples de fonctions de perte:
  - Erreur quadratique (pour `\(y \in \mathbb{R}\)`):
  \begin{align}
    \ell(y, \widehat{y}) = (y - \widehat{y})^2 
  \end{align}
  - Entropie croisée binaire (pour `\(y \in \{0, 1\}\)`):
  \begin{align}
    \ell(y, \widehat{y}) = \left[y \ln(\widehat{y}) + (1-y) \ln(1-\widehat{y})\right]
  \end{align}
  - Moins la log-vraisemblance Poisson pour données de comptage:
  \begin{align}
    \ell(y, \widehat{y}) = \left[-\widehat{y} + y\ln(\widehat{y})\right]
  \end{align}
- Le but est alors de minimiser la fonction de perte moyenne sur l'ensemble d'entrainement, qu'on appelle parfois **risque empirique**. On voudra donc trouver les paramètres qui minimisent `\(\frac{1}{n}\sum_{i=1}^n \ell(y_i, \widehat{y}_i)\)`.
`$$\DeclareMathOperator*{\argmin}{argmin}$$`

???

- Entrainer un réseau de neurones signifie trouver de bonnes valeurs pour ses paramètres.
- De bonnes valeurs de paramètres sont des valeurs qui mènent à des prédictions `\(\widehat{y}\)` « proches » de la vraie valeur `\(y\)`.
- Pour définir « proche », on choisit une fonction de perte, qui mesure la distance entre une réponse `\(y\)` et sa prédiction `\(\widehat{y}\)`.
- On vise à minimiser la fonction de perte moyenne prise sur toutes les observations de l'ensemble d'entrainement.

---

# Entrainer un réseau de neurones

## Minimisation du risque empirique

- Le but est donc de trouver les paramètres `\(\boldsymbol{w}^*\)` qui minimisent le risque empirique:
`\begin{align}
  \boldsymbol{w}^* &amp;= \argmin_\boldsymbol{w} \frac{1}{n}\sum_{i=1}^n \ell(y, \widehat{y})\\
  &amp;= \argmin_\boldsymbol{w} \frac{1}{n}\sum_{i=1}^n \ell(y, f(\boldsymbol{x}_i; \boldsymbol{w}))\\
  &amp;= \argmin_\boldsymbol{w} J(\boldsymbol{w})
\end{align}`

- Avec les GLMs, on dérivait par rapport aux paramètres et on égalait à zéro pour trouver le minimum.
- Cette méthode ne fonctionne pas ici, car rien ne garantit que la fonction de risque empirique `\(J\)` est convexe!
- On utilise plutôt la **descente de gradient** (et ses dérivées).

???

- Le but est de trouver les paramètres `\(\boldsymbol{w}^*\)` qui minimisent le risque empirique `\(J\)`.
- On ne peut pas simplement calculer la dérivée de la fonction `\(J\)` par rapport aux paramètres `\(\boldsymbol{w}\)` et égaler à zéro pour trouver le minimum comme on faisait avec les GLMs, car la fonction `\(J\)` n'est jamais convexe (sauf peut-être dans quelques cas simples comme le perceptron à 0 couche cachée) et a souvent plusieurs minimums locaux et des points de selle.
- Pour les réseaux de neurones, on utilise donc habituellement des méthodes basées sur la descente de gradient. 

---

# Entrainer un réseau de neurones

## Descente de gradient

.pull-left[
&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="images/gradient_descent.gif" alt="Fonction de risque empirique en fonction des paramètres. Note: ici, les paramètres sont dénotés par la lettre grecque theta." width="100%" /&gt;
&lt;p class="caption"&gt;Fonction de risque empirique en fonction des paramètres. Note: ici, les paramètres sont dénotés par la lettre grecque theta.&lt;/p&gt;
&lt;/div&gt;
]

.pull-right[
**Pseudo-algorithme:**&lt;br&gt;
1. Initialiser les paramètres `\((w_0, w_1)\)` au hasard
2. Calculer le gradient de la fonction de risque au point `\((w_0, w_1)\)`
3. Bouger dans la direction opposée du gradient (le gradient pointe vers le haut de la fonction alors qu'on veut aller vers le bas)
4. Répéter jusqu'à convergence
]

---

# Entrainer un réseau de neurones

## Descente de gradient

**Algorithme**

1. Initialiser les paramètres `\(\boldsymbol{w}\)` au hasard `\(\sim\mathcal{N}(0, \sigma^2)\)`
2. Répéter jusqu'à convergence:
  - Calculer le gradient `\(\frac{\partial J(\boldsymbol{w})}{\partial \boldsymbol{w}}\)`
  - Mettre à jour les paramètres: `\(\boldsymbol{w} \leftarrow \boldsymbol{w} - \eta \frac{\partial J(\boldsymbol{w})}{\partial \boldsymbol{w}}\)`
3. Output: paramètres `\(\boldsymbol{w}\)`
---

# Entrainer un réseau de neurones

## Minimisation du risque empirique






    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
